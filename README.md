# 2024-mimic-benchmarking

[![run with conda](http://img.shields.io/badge/run%20with-conda-3EB049?labelColor=000000&logo=anaconda)](https://docs.conda.io/projects/miniconda/en/latest/)
[![Snakemake](https://img.shields.io/badge/snakemake--green)](https://snakemake.readthedocs.io/en/stable/)

## Purpose
This repository contains standardized datasets that we are using to evaluate protein structural alignment methods and how they impact our results. These datasets include the following:
- Sets of structures for randomly selected human proteins (50, 100, 500, 1000)
- Sets of random selected viral protein structures (50, 100, 500, 1000) predicted by [Viro3D](https://viro3d.cvr.gla.ac.uk)
- 'Target' protein pdbs for proteins of interest from human, chimp, macaque, and mouse. Viruses have been shown to mimic these proteins.
- Viral representative sequences for each of the 4 target proteins. At least one protein in each set is the exact viral protein that was confirmed via experimentation to mimic the human protein.
  
## Installation and Setup

This repository uses Snakemake to run the pipeline and conda to manage software environments and installations. You can find operating system-specific instructions for installing miniconda [here](https://docs.conda.io/projects/miniconda/en/latest/). After installing conda and [mamba](https://mamba.readthedocs.io/en/latest/), run the following command to create the pipeline run environment.

```{bash}
mamba env create -n benchmark --file envs/dev.yml
conda activate benchmark
```

Snakemake manages rule-specific environments via the `conda` directive and using environment files in the [envs/](./envs/) directory. Snakemake itself is installed in the main development conda environment as specified in the [dev.yml](./envs/dev.yml) file.

To start the pipeline, run:

```{bash}
snakemake --software-deployment-method conda -j 8
```


## Benchmarking data

- We downloaded target protein pdbs directly from [Alphafold](https://alphafold.ebi.ac.uk/) using UniProt accessions.
- We downloaded viral protein structures from human-infecting viruses from [Viro3D](https://viro3d.cvr.gla.ac.uk) by the running the [get_all_viral_structures.snakefile](get_all_viral_structures.snakefile).
- We generated random viral protein datasets by running the [create_random_viral_sets.snakefile](create_random_viral_sets.snakefile).
- We generated random human protein datasets by running the [create_random_human_sets.snakefile](create_random_human_sets.snakefile). Note that this file exists as documentation for how we generated these steps, but there is a non-deterministic step that produce different sets if the snakefile is re-run. As such, please **use the data in the [benchmarking_data](benchmarking_data) folder if you plan to use these datasets**.

The [benchmarking_data](./benchmarking_data) folder contains the sets of viral and other species [positive control pdbs](./benchmarking_data/positive_controls) for the four target proteins as well as the sets of [random human and random viral protein structures](./benchmarking_data/random_protein_sets).

## Benchmarking tests

### Positive controls

We designed the [positive_control_benchmarking.snakefile](positive_control_benchmarking.snakefile) to test which structural comparison tools maximized true positive hits while minimizing false positive hits.
We used viral and Eukaryotic protein structures for four proteins (IL18BP, C4BP, IL10, EIF2A) and compared each structure against all human proteins (UniProt proteome with single structures in AlphaFold database).
We used foldseek and gtalign to perform these comparisons.
For gtalign, we tested speeds 0 (most sensitive, slowest) and 9 (default).
For foldseek, we tested the all combinations of the parameters:
* `--alignment-type`
    * `1`: TMAlign mode. This parameter makes the biggest difference on speed and accuracy for foldseek results. It increases the accuracy and decreases the speed.
    * `2`: 3di + AA mode. This is the default foldseek algorithm. It converts each structure into an alphabet, decomposes the alphabatized structure into k-mers, and then performs operations on those k-mers.
* `--tmalign-fast`. This parameter makes the second biggest difference on speed and accuracy for foldseek results generated by TMAlign mode. Turning fast mode OFF increases the accuracy and decreases the speed. I think the accuracy gains are biggest for matches with a TM-score < 0.5. This parameter is only impactful for `--alignment-type 1` (TMAlign mode).
    * `0`: Off. Don't use fast most.
    * `1`: On. Use fast mode.
* `--exact-tmscore`: This parameter makes the second biggest difference on speed and accuracy for foldseek results generated by TMAlign mode. Turning fast mode OFF increases the accuracy and decreases the speed. I think the accuracy gains are biggest for matches with a TM-score < 0.5
    * `0`: Off. Don't calculate exact TM-scores.
    * `1`: On. Calculate exact TM-scores.
* `--tmscore-threshold`
    * `0`: TM-score threshold is set to 0. This lowers the threshold for a match to be returned, but on it's own does not turn on exhaustive searching. 
    * `0.25`: TM-score threshold is set of 0.25. When compared to an exhaustive search, not all hits with a 0.25 will actually be returned. Using a TM-score threshold of 0.25 allows us to better recover hits that have a real TM-score of > 0.5, which is the hits we care about for viruses. It's not actually clear which TM-score the thresholding is acting on (alignment, query, or target). In an unreleased version of foldseek, the user can set the mode and the default is alignment tm-score.
* `--exhaustive-search`
    * `0` (off): Do not perform an exhaustive search. Uses default pre-filtering instead.
    * `1` (on): Perform an exhaustive search. However, exhaustive searching will be disabled when combined with tmscore-threshold 0.25.

## Compute specifications

We ran the [create_random_viral_sets.snakefile](create_random_viral_sets.snakefile) and the [create_random_human_sets.snakefile](create_random_human_sets.snakefile) on an MacBook computer.

We ran the [positive_control_benchmarking.snakefile](positive_control_benchmarking.snakefile) on an AWS EC2 instance type g4dn.2xlarge running AMI Deep Learning Base OSS Nvidia Driver GPU AMI (Ubuntu 20.04) 20240122 (AMI ID ami-07eb000b3340966b0).
The tool gtalign can use a GPU so compute times will be substantially faster on a GPU than a CPU.
We did not test the pipeline on a CPU so there is a chance it will only work on a GPU.

## Contributing

See how we recognize [feedback and contributions to our code](https://github.com/Arcadia-Science/arcadia-software-handbook/blob/main/guides-and-standards/guide-credit-for-contributions.md).
